= Installing Bosh Director
Eitan Suez <esuez@pivotal.io>
v0.1, 2017
:project_id: {{project_id}}
:domain_name: {{domain_name}}
:env_name: {{env_name}}
:director_ip_address: {{director_ip_address}}


The terraform scripts we ran in the last lab created the Ops Manager VM.

The two main tasks we will accomplish in this lab are:

. setup access to Ops Manager, by selecting a username and password (and passphrase)
. use the Ops Manager to configure the BOSH Director.

Setting up the BOSH Director is a prerequisite step to installing Cloud Foundry.

== DNS configuration

Before we can access our Ops Manager, your instructor will need to create an NS record (from their top-level domain's zone) for your subdomain `{env_name}.{domain_name}`.

In the Google Cloud Console, navigate to Networking -> Cloud DNS; you should see a zone named _{env_name}-zone_ listed.

Click on the zone; you'll notice an NS-type entry for the subdomain, as shown below.

[.thumb]
.Cloud DNS view of your hosted zone
image::hosted_zone.png[Cloud DNS]

Communicate the value of the _Data_ column to your instructor (which should be a list of google name servers).

Shortly after the NS record is created, you should be able to verify proper DNS resolution for any host under your subdomain using a client such as `dig` or `nslookup`.


== Instructions

The Ops Manager runs a web server that is accessible at https://pcf.{env_name}.{domain_name}/[^].

. Open a web browser and visit that page.

. follow the http://docs.pivotal.io/pivotalcf/customizing/gcp-om-config.html[Configuring Ops Manager^] instructions from the PCF documentation

Make the following selections as you work through setting up the director:

=== Access Ops Manager

Select the "internal authentication" method when setting up access to your Ops Manager.  Select a username, password, passphrase.

=== GCP Config

On http://docs.pivotal.io/pivotalcf/customizing/gcp-om-config.html#gcp-config[this step^], just specify your project id ({project_id}) and press Save.

NOTE:  I have in the past run into an issue here where the error message states that my ops manager service account cannot find my GCP project.  Resolve this issue by navigating in the IAM & Admin -> Service Account section of your Google Cloud Console.  Note the id of the service account that was created by the terraform script: it should be `gcp-opsman@{{project_id}}.iam.gserviceaccount.com`.  Copy that service account ID.  Now visit the IAM section, where we can set permissions for accounts.  If the gcp-opsman entry is already there, remove it, and add it back, giving it the permissions _Compute Instance Admin_, _Compute Network Admin_, _Compute Security Admin_, _Compute Storage Admin_, _Storage Admin_, and _Service Account For_ (don't forget to press "Save").


=== Director Config

See http://docs.pivotal.io/pivotalcf/customizing/gcp-om-config.html#director-config[instructions section^].

. Enable VM Resurrector plugin (check)
. Enable _post deploy scripts_ (check)
. Skip the pager duty and email plugins configuration

Press _Save_.

=== Create Availability Zones

See http://docs.pivotal.io/pivotalcf/customizing/gcp-om-config.html#az[instructions section^].

Create three availability zones (e.g. us-central1-a, us-central1-b, us-central1-c).

[.thumb]
.Availability Zone Configuration
image::az_config.png[Availability Zone Configiuration]

Press _Save_.


=== Create Networks

See http://docs.pivotal.io/pivotalcf/customizing/gcp-om-config.html#network[instructions section^].

Create three networks to match the three subnets that were created by the terraform scripts.  Here's an example configuration for the elastic runtime network:

[.thumb]
.Example Network Configuration: Elastic Runtime
image::ert_network_config.png[Example Network Configuration,width="50%"]


=== Assign AZs and Newtorks

. Select the `{env_name}-ops-manager-subnet` in http://docs.pivotal.io/pivotalcf/customizing/gcp-om-config.html#assign-azs[step 6^]:  that's the subnet in which the bosh director should be installed

Press _Save_.

=== Apply Changes

Go back to the installation dashboard and click _Apply Changes_.  It may take up to ten minutes for this to finish. This may be a good time to stretch and grab a cup of coffee.

In the Google Cloud Console, visit the _Compute Engine -> VM Instances_ section and observe that a new VM will have been created for the BOSH Director.

Congratulations, you have now deployed the BOSH Director.

== Post-Installation

. in the Ops Manager, select the GCP _tile_.  We need to retrieve some information:
.. the Ops Manager IP address: navigate to the _Status_ tab, note the IP address for the Ops Manager Director
.. navigate to the _Credentials_ tab, click the link to the director credentials, note the identity and password displayed in the json response.

. verify that you can ssh into the Ops Manager with:
+
[source.terminal]
----
gcloud compute ssh ubuntu@{{env_name}}-ops-manager
----
+
NOTE: The above command dynamically creates a key pair for logging in to the VM
+
The bosh client is pre-installed on Ops Manager VM.  For security, the bosh director VM is usually not made accessible from the outside world.  The Ops Manager VM serves as a bastion VM from which we can communicate with the bosh director.

. Target, and login to the bosh director:
+
[source.terminal]
----
bosh --ca-cert /var/tempest/workspaces/default/root_ca_certificate target {{director_ip_address}}
----
+
When prompted to log in, enter `director` for the user name, and the previously noted secret for the password.

. Invoke the following command:
+
[source.terminal]
----
bosh deployments
----
+
The response should be empty at the moment, as we have not yet used the bosh director to deploy anything.

You may now log out of the Ops Manager.

Congratulations, you have verified the proper functioning of the bosh director and are now ready to move on to installing the elastic runtime (our next lab).
