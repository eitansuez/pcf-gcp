= Installing Bosh Director
Eitan Suez <esuez@pivotal.io>
v0.1, 2017
:domain_name: {{domain_name}}
:env_name: {{env_name}}
:director_ip_address: {{director_ip_address}}


The terraform scripts we ran in the last lab created the Ops Manager VM.

The two main tasks we will accomplish in this lab are:

. setup access to Ops Manager, by selecting a username and password (and passphrase)
. use the Ops Manager to configure the BOSH Director.

Setting up the BOSH Director is a prerequisite step to installing Cloud Foundry.

== DNS configuration

Before we can access our Ops Manager, your instructor will need to create an NS record (from their top-level domain's zone) for your subdomain `{env_name}.{domain_name}`.

In the Google Cloud Console, navigate to Networking -> Cloud DNS; you should see a zone named _{env_name}-zone_ listed.

Click on the zone; you'll notice an NS-type entry for the subdomain, as shown below.

[.thumb]
.Cloud DNS view of your hosted zone
image::hosted_zone.png[Cloud DNS]

-> Communicate the value of the _Data_ column to your instructor (which should be a list of google name servers).

Shortly after the NS record is created, you should be able to verify proper DNS resolution for any host under your subdomain using a client such as `dig` or `nslookup`.


== Instructions

The Ops Manager runs a web server that is accessible at https://pcf.{env_name}.{domain_name}/[^].

. Open a web browser and visit that page.

. follow the http://docs.pivotal.io/pivotalcf/customizing/gcp-om-config.html[Configuring Ops Manager^] instructions from the PCF documentation

Make the following selections as you work through setting up the director:

. select the "internal authentication" method when setting up access to your Ops Manager
. enable VM Resurrector plugin (check)
. enable _post deploy scripts_ (check)
. skip the pager duty and email plugins configuration
. create three availability zones
. create three networks to match the three subnets that were created by the terraform scripts
. select the `{env_name}-ops-manager-subnet` in step 6:  that's the subnet in which the bosh director should be installed
. apply changes, it may take up to ten minutes for this to finish.

In the Google Cloud Console, visit the _Compute Engine -> VM Instances_ section and observe that a new VM will have been created for the BOSH Director.

Congratulations, you have now deployed the BOSH Director.

== Post-Installation

. in the Ops Manager, select the GCP _tile_.  We need to retrieve some information:
.. the Ops Manager IP address: navigate to the _Status_ tab, note the IP address for the Ops Manager Director
.. navigate to the _Credentials_ tab, click the link to the director credentials, note the identity and password displayed in the json response.

. verify that you can ssh into the Ops Manager with:
+
[source.terminal]
----
gcloud compute ssh ubuntu@{{env_name}}-ops-manager
----
+
NOTE: The above command dynamically creates a key pair for logging in to the VM
+
The bosh client is pre-installed on Ops Manager VM.  For security, the bosh director VM is usually not made accessible from the outside world.  the Ops Manager VM serves as a bastion VM from which we can communicate with the bosh director.

. target, and login to the bosh director:
+
[source.terminal]
----
bosh --ca-cert /var/tempest/workspaces/default/root_ca_certificate target {{director_ip_address}}
----
+
When prompted to log in, enter `director` for the user name, and the previously noted secret for the password.

. Invoke the following command:
+
[source.terminal]
----
bosh deployments
----
+
The response should be empty at the moment, as we have not yet used the bosh director to deploy anything.

You may now log out of the Ops Manager.

Congratulations, you have verified the proper functioning of the bosh director and are now ready to move on to installing the elastic runtime (our next lab).
